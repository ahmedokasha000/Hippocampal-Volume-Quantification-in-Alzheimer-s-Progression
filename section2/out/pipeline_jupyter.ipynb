{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains code that will kick off training and testing processes\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "from experiments.UNetExperiment import UNetExperiment\n",
    "from data_prep.HippocampusDatasetLoader import LoadHippocampusData\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    Holds configuration parameters\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Basic_unet\"\n",
    "        self.root_dir = r\"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section1/out/TrainingSet\"\n",
    "        self.n_epochs = 10\n",
    "        self.learning_rate = 0.0002\n",
    "        self.batch_size = 8\n",
    "        self.patch_size = 64\n",
    "        self.test_results_dir = \"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section2/out\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get configuration\n",
    "    #del data\n",
    "\n",
    "    # TASK: Fill in parameters of the Config class and specify directory where the data is stored and \n",
    "    # directory where results will go\n",
    "    c = Config()\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    # TASK: LoadHippocampusData is not complete. Go to the implementation and complete it. \n",
    "    data = LoadHippocampusData(c.root_dir, y_shape = c.patch_size, z_shape = c.patch_size)\n",
    "    # Create test-train-val split\n",
    "    # In a real world scenario you would probably do multiple splits for \n",
    "    # multi-fold training to improve your model quality\n",
    "\n",
    "    keys =[x for x in range(len(data))] #range(len(data))\n",
    "\n",
    "    # Here, random permutation of keys array would be useful in case if we do something like \n",
    "    # a k-fold training and combining the results. \n",
    "    split = dict()\n",
    "    # and testing respectively.    # TASK: create three keys in the dictionary: \"train\", \"val\" and \"test\". In each key, store\n",
    "    # the array with indices of training volumes to be used for train\n",
    "    #print(\"dataset length\",len(data))\n",
    "    tr_end=int(0.6*len(data))\n",
    "    val_end=int(0.8*len(data))\n",
    "    train_keys=keys[:tr_end]\n",
    "    val_keys=keys[tr_end:val_end]\n",
    "    test_keys=keys[val_end:]\n",
    "    print(len(train_keys),len(val_keys),len(test_keys))\n",
    "    split[\"train\"],split[\"val\"],split[\"test\"]=np.split(keys,[tr_end,val_end])\n",
    "    # Set up and run experiment\n",
    "#     print(\"validation len\",len(split[\"val\"]))\n",
    "#     print(\"test le\",len(split[\"test\"]))\n",
    "    # TASK: Class UNetExperiment has missing pieces. Go to the file and fill them in\n",
    "    exp = UNetExperiment(c, split, data)\n",
    "\n",
    "    # You could free up memory by deleting the dataset\n",
    "    # as it has been copied into loaders\n",
    "    # run training\n",
    "    exp.run()\n",
    "\n",
    "    # prep and run testing\n",
    "    # TASK: Test method is not complete. Go to the method and complete it\n",
    "    results_json = exp.run_test()\n",
    "    results_json[\"config\"] = vars(c)\n",
    "    with open(os.path.join(exp.out_dir, \"results.json\"), 'w') as out_file:\n",
    "        json.dump(results_json, out_file, indent=2, separators=(',', ': '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate interface Part to avoid retraining the model if interface was hanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 260 files, total 9198 slices\n",
      "torch.Size([32, 1, 64, 64])\n",
      "hippocampus_216.nii.gz Dice 0.8943. 3.33% complete\n",
      "torch.Size([38, 1, 64, 64])\n",
      "hippocampus_217.nii.gz Dice 0.8366. 6.67% complete\n",
      "torch.Size([37, 1, 64, 64])\n",
      "hippocampus_219.nii.gz Dice 0.8829. 10.00% complete\n",
      "torch.Size([39, 1, 64, 64])\n",
      "hippocampus_220.nii.gz Dice 0.8932. 13.33% complete\n",
      "torch.Size([32, 1, 64, 64])\n",
      "hippocampus_221.nii.gz Dice 0.7579. 16.67% complete\n",
      "torch.Size([34, 1, 64, 64])\n",
      "hippocampus_222.nii.gz Dice 0.8126. 20.00% complete\n",
      "torch.Size([35, 1, 64, 64])\n",
      "hippocampus_223.nii.gz Dice 0.8727. 23.33% complete\n",
      "torch.Size([37, 1, 64, 64])\n",
      "hippocampus_224.nii.gz Dice 0.8659. 26.67% complete\n",
      "torch.Size([33, 1, 64, 64])\n",
      "hippocampus_225.nii.gz Dice 0.8530. 30.00% complete\n",
      "torch.Size([32, 1, 64, 64])\n",
      "hippocampus_226.nii.gz Dice 0.8359. 33.33% complete\n",
      "torch.Size([36, 1, 64, 64])\n",
      "hippocampus_227.nii.gz Dice 0.8954. 36.67% complete\n",
      "torch.Size([37, 1, 64, 64])\n",
      "hippocampus_228.nii.gz Dice 0.8321. 40.00% complete\n",
      "torch.Size([36, 1, 64, 64])\n",
      "hippocampus_326.nii.gz Dice 0.8455. 43.33% complete\n",
      "torch.Size([36, 1, 64, 64])\n",
      "hippocampus_327.nii.gz Dice 0.8950. 46.67% complete\n",
      "torch.Size([38, 1, 64, 64])\n",
      "hippocampus_328.nii.gz Dice 0.9011. 50.00% complete\n",
      "torch.Size([34, 1, 64, 64])\n",
      "hippocampus_329.nii.gz Dice 0.8368. 53.33% complete\n",
      "torch.Size([35, 1, 64, 64])\n",
      "hippocampus_330.nii.gz Dice 0.7485. 56.67% complete\n",
      "torch.Size([35, 1, 64, 64])\n",
      "hippocampus_331.nii.gz Dice 0.8646. 60.00% complete\n",
      "torch.Size([35, 1, 64, 64])\n",
      "hippocampus_332.nii.gz Dice 0.8887. 63.33% complete\n",
      "torch.Size([33, 1, 64, 64])\n",
      "hippocampus_333.nii.gz Dice 0.7947. 66.67% complete\n",
      "torch.Size([34, 1, 64, 64])\n",
      "hippocampus_334.nii.gz Dice 0.7888. 70.00% complete\n",
      "torch.Size([32, 1, 64, 64])\n",
      "hippocampus_335.nii.gz Dice 0.8465. 73.33% complete\n",
      "torch.Size([34, 1, 64, 64])\n",
      "hippocampus_336.nii.gz Dice 0.8485. 76.67% complete\n",
      "torch.Size([33, 1, 64, 64])\n",
      "hippocampus_337.nii.gz Dice 0.8616. 80.00% complete\n",
      "torch.Size([37, 1, 64, 64])\n",
      "hippocampus_338.nii.gz Dice 0.8518. 83.33% complete\n",
      "torch.Size([35, 1, 64, 64])\n",
      "hippocampus_340.nii.gz Dice 0.8469. 86.67% complete\n",
      "torch.Size([34, 1, 64, 64])\n",
      "hippocampus_341.nii.gz Dice 0.8695. 90.00% complete\n",
      "torch.Size([32, 1, 64, 64])\n",
      "hippocampus_343.nii.gz Dice 0.8690. 93.33% complete\n",
      "torch.Size([32, 1, 64, 64])\n",
      "hippocampus_345.nii.gz Dice 0.8659. 96.67% complete\n",
      "torch.Size([34, 1, 64, 64])\n",
      "hippocampus_349.nii.gz Dice 0.8539. 100.00% complete\n",
      "\n",
      "Testing complete.\n",
      "CPU times: user 3min 39s, sys: 8.17 s, total: 3min 47s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.cm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "from inference.UNetInferenceAgent import UNetInferenceAgent\n",
    "from utils.volume_stats import Dice3d,Jaccard3d\n",
    "import torch\n",
    "path=\"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section1/out/TrainingSet\"\n",
    "data = LoadHippocampusData(path, y_shape = 64, z_shape = 64)\n",
    "images_t=data[230:]\n",
    "\n",
    "out_dict = {}\n",
    "out_dict[\"volume_stats\"] = []\n",
    "dc_list = []\n",
    "\n",
    "jc_list = []\n",
    "inference_agent = UNetInferenceAgent(\"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section2/out/2020-05-30_1018_Basic_unet/model.pth\")\n",
    "with torch.no_grad():\n",
    "    for i, x in enumerate(images_t):\n",
    "        pred_label = inference_agent.single_volume_inference(x[\"image\"])\n",
    "        dc = Dice3d(pred_label, x[\"seg\"])\n",
    "        jc = Jaccard3d(pred_label, x[\"seg\"])\n",
    "        dc_list.append(dc)\n",
    "        jc_list.append(jc)\n",
    "        out_dict[\"volume_stats\"].append({\n",
    "            \"filename\": x['filename'],\n",
    "            \"dice\": dc,\n",
    "            \"jaccard\": jc\n",
    "            })\n",
    "        print(f\"{x['filename']} Dice {dc:.4f}. {100*(i+1)/len(images_t):.2f}% complete\")\n",
    "out_dict[\"overall\"] = {\n",
    "    \"mean_dice\": np.mean(dc_list),\n",
    "    \"mean_jaccard\": np.mean(jc_list)}\n",
    "\n",
    "print(\"\\nTesting complete.\")\n",
    "out_dir= \"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section2/out\"\n",
    "with open(os.path.join(out_dir, \"results.json\"), 'w') as out_file:\n",
    "    json.dump(out_dict, out_file, indent=2, separators=(',', ': '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "figure,axes=plt.subplots(20,3,figsize=(10,40))\n",
    "axes=axes.flatten()\n",
    "for ind in range(20):\n",
    "    axes[ind*3].imshow(pred_label[ind,0,:,:],cmap='gray')\n",
    "    axes[ind*3+1].imshow(pred_label[ind,1,:,:],cmap='gray')\n",
    "    axes[ind*3+2].imshow(pred_label[ind,2,:,:],cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
