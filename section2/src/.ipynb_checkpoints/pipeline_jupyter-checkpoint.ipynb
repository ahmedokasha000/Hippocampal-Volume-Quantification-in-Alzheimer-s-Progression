{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Processed 64 files, total 2281 slices\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5c3ada10191b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtrain_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtrain_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mval_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mval_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[:int(len(val_keys)*ratio)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file contains code that will kick off training and testing processes\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "from experiments.UNetExperiment import UNetExperiment\n",
    "from data_prep.HippocampusDatasetLoader import LoadHippocampusData\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    Holds configuration parameters\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"Basic_unet\"\n",
    "        self.root_dir = r\"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section1/out/TrainingSet\"\n",
    "        self.n_epochs = 10\n",
    "        self.learning_rate = 0.0006\n",
    "        self.batch_size = 8\n",
    "        self.patch_size = 64\n",
    "        self.test_results_dir = \"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section2/out\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get configuration\n",
    "    #del data\n",
    "\n",
    "    # TASK: Fill in parameters of the Config class and specify directory where the data is stored and \n",
    "    # directory where results will go\n",
    "    c = Config()\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "\n",
    "    # TASK: LoadHippocampusData is not complete. Go to the implementation and complete it. \n",
    "    data = LoadHippocampusData(c.root_dir, y_shape = c.patch_size, z_shape = c.patch_size)\n",
    "\n",
    "\n",
    "    # Create test-train-val split\n",
    "    # In a real world scenario you would probably do multiple splits for \n",
    "    # multi-fold training to improve your model quality\n",
    "\n",
    "    keys =[x for x in range(len(data))] #range(len(data))\n",
    "    #keys =range(64)\n",
    "    \n",
    "    # Here, random permutation of keys array would be useful in case if we do something like \n",
    "    # a k-fold training and combining the results. \n",
    "\n",
    "    split = dict()\n",
    "\n",
    "    # and testing respectively.    # TASK: create three keys in the dictionary: \"train\", \"val\" and \"test\". In each key, store\n",
    "    # the array with indices of training volumes to be used for train\n",
    "    #print(\"dataset length\",len(data))\n",
    "    ratio=0.25\n",
    "    tr_end=int(0.6*len(data))\n",
    "    val_end=int(0.8*len(data))\n",
    "    train_keys=keys[:tr_end]\n",
    "    np.random.shuffle(train_keys)\n",
    "    train_keys=train_keys[:int(len(train_keys)*ratio)]\n",
    "    val_keys=keys[tr_end:val_end]\n",
    "    (np.random.shuffle(val_keys))#[:int(len(val_keys)*ratio)]\n",
    "    test_keys=keys[val_end:]\n",
    "    test_keys=(np.random.shuffle(test_keys))[:int(len(test_keys)*ratio)]\n",
    "    print(len(train_keys),len(val_keys),len(test_keys))\n",
    "    split[\"train\"],split[\"val\"],split[\"test\"]=np.split(keys,[tr_end,val_end])\n",
    "    # Set up and run experiment\n",
    "#     print(\"validation len\",len(split[\"val\"]))\n",
    "#     print(\"test le\",len(split[\"test\"]))\n",
    "    # TASK: Class UNetExperiment has missing pieces. Go to the file and fill them in\n",
    "    exp = UNetExperiment(c, split, data)\n",
    "\n",
    "    # You could free up memory by deleting the dataset\n",
    "    # as it has been copied into loaders\n",
    "     \n",
    "\n",
    "    # run training\n",
    "    exp.run()\n",
    "\n",
    "    # prep and run testing\n",
    "\n",
    "    # TASK: Test method is not complete. Go to the method and complete it\n",
    "    results_json = exp.run_test()\n",
    "\n",
    "    results_json[\"config\"] = vars(c)\n",
    "\n",
    "    with open(os.path.join(exp.out_dir, \"results.json\"), 'w') as out_file:\n",
    "        json.dump(results_json, out_file, indent=2, separators=(',', ': '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.cm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "from inference.UNetInferenceAgent import UNetInferenceAgent\n",
    "import torch\n",
    "inference_agent = UNetInferenceAgent(\"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section2/out/2020-05-28_1641_Basic_unet/model.pth\")\n",
    "image_dir = r\"/media/ahmed000/Personal/Learning/DeepLearning/projects/AI_for_HC_ND/Third_course/final_project/section1/out/TrainingSet/images/hippocampus_001.nii.gz\"\n",
    "image_t,_=load(image_dir)\n",
    "image_t=(image_t.astype(np.single))/np.max(image_t)\n",
    "with torch.no_grad():\n",
    "        pred_label = inference_agent.single_volume_inference(image_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "figure,axes=plt.subplots(20,3,figsize=(10,40))\n",
    "axes=axes.flatten()\n",
    "for ind in range(20):\n",
    "    axes[ind*3].imshow(pred_label[ind,0,:,:],cmap='gray')\n",
    "    axes[ind*3+1].imshow(pred_label[ind,1,:,:],cmap='gray')\n",
    "    axes[ind*3+2].imshow(pred_label[ind,2,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Module loads the hippocampus dataset into RAM\n",
    "# \"\"\"\n",
    "# import os\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# import numpy as np\n",
    "# from medpy.io import load\n",
    "\n",
    "# from utils.utils import med_reshape\n",
    "\n",
    "# def LoadHippocampusData(root_dir, y_shape, z_shape):\n",
    "#     '''\n",
    "#     This function loads our dataset form disk into memory,\n",
    "#     reshaping output to common size\n",
    "\n",
    "#     Arguments:\n",
    "#         volume {Numpy array} -- 3D array representing the volume\n",
    "\n",
    "#     Returns:\n",
    "#         Array of dictionaries with data stored in seg and image fields as \n",
    "#         Numpy arrays of shape [AXIAL_WIDTH, Y_SHAPE, Z_SHAPE]\n",
    "#     '''\n",
    "\n",
    "#     image_dir = os.path.join(root_dir, 'images')\n",
    "#     label_dir = os.path.join(root_dir, 'labels')\n",
    "        \n",
    "    \n",
    "#     images = [f for f in listdir(image_dir) if (\n",
    "#         isfile(join(image_dir, f)) and f[0] != \".\")]\n",
    "#     #### This part is built to shuffle each study with it's label \n",
    "#     # add limit the number of batches per epoch\n",
    "#     rng_state = np.random.get_state()\n",
    "#     np.random.shuffle(images)\n",
    "#     #np.random.set_state(rng_state)\n",
    "#     #np.random.shuffle(y)\n",
    "#     out = []\n",
    "#     ######## change\n",
    "#     for f in images[:64]:\n",
    "\n",
    "#         # We would benefit from mmap load method here if dataset doesn't fit into memory\n",
    "#         # Images are loaded here using MedPy's load method. We will ignore header \n",
    "#         # since we will not use it\n",
    "#         ## loading all dataset images to clean it\n",
    "#         image, _ = load(os.path.join(image_dir, f))\n",
    "#         label, _ = load(os.path.join(label_dir, f))\n",
    "        \n",
    "#         # TASK: normalize all images (but not labels) so that values are in [0..1] range\n",
    "#         image =(image.astype(np.single))/ np.max(image)\n",
    "#         # We need to reshape data since CNN tensors that represent minibatches\n",
    "#         # in our case will be stacks of slices and stacks need to be of the same size.\n",
    "#         # In the inference pathway we will need to crop the output to that\n",
    "#         # of the input image.\n",
    "#         # Note that since we feed individual slices to the CNN, we only need to \n",
    "#         # extend 2 dimensions out of 3. We choose to extend coronal and sagittal here\n",
    "\n",
    "#         # TASK: med_reshape function is not complete. Go and fix it!\n",
    "#         image = med_reshape(image, new_shape=(image.shape[0], y_shape, z_shape)).astype(np.single)\n",
    "#         label = med_reshape(label, new_shape=(label.shape[0], y_shape, z_shape)).astype(np.int_)\n",
    "\n",
    "#         # TASK: Why do we need to cast label to int?\n",
    "#         # ANSWER: Because labels should be integer values to be identified as \n",
    "#         # diiferent classes when fed to pytorch. Also pytorch will not accept labels as float\n",
    "\n",
    "#         out.append({\"image\": image, \"seg\": label, \"filename\": f})\n",
    "\n",
    "#     # Hippocampus dataset only takes about 300 Mb RAM, so we can afford to keep it all in RAM\n",
    "#     print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n",
    "#     return np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Module for Pytorch dataset representations\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# class SlicesDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     This class represents an indexable Torch dataset\n",
    "#     which could be consumed by the PyTorch DataLoader class\n",
    "#     \"\"\"\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "\n",
    "#         self.slices = []\n",
    "\n",
    "#         for i, d in enumerate(data):\n",
    "#             for j in range(d[\"image\"].shape[0]):\n",
    "#                 self.slices.append((i, j))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"\n",
    "#         This method is called by PyTorch DataLoader class to return a sample with id idx\n",
    "\n",
    "#         Arguments: \n",
    "#             idx {int} -- id of sample\n",
    "\n",
    "#         Returns:\n",
    "#             Dictionary of 2 Torch Tensors of dimensions [1, W, H]\n",
    "#         \"\"\"\n",
    "#         slc = self.slices[idx]\n",
    "#         sample = dict()\n",
    "#         sample[\"id\"] = idx\n",
    "#         #print(\"sample id\",sample[\"id\"])\n",
    "#         # You could implement caching strategy here if dataset is too large to fit\n",
    "#         # in memory entirely\n",
    "#         # Also this would be the place to call transforms if data augmentation is used\n",
    "        \n",
    "#         # TASK: Create two new keys in the \"sample\" dictionary, named \"image\" and \"seg\"\n",
    "#         # The values are 3D Torch Tensors with image and label data respectively. \n",
    "#         # First dimension is size 1, and last two hold the voxel data from the respective\n",
    "#         # slices. Write code that stores the 2D slice data in the last 2 dimensions of the 3D Tensors. \n",
    "#         # Your tensor needs to be of shape [1, patch_size, patch_size]\n",
    "#         # Don't forget that you need to put a Torch Tensor into your dictionary element's value\n",
    "#         # Hint: your 3D data sits in self.data variable, the id of the 3D volume from data array\n",
    "#         # and the slice number are in the slc variable. \n",
    "#         # Hint2: You can use None notation like so: arr[None, :] to add size-1 \n",
    "#         # dimension to a Numpy array\n",
    "#         vol_id,slice_n=slc\n",
    "#         #print(\"slice = \",slc[0],slc[1])\n",
    "\n",
    "#         sample[\"img\"]=torch.from_numpy((self.data[vol_id][\"image\"])[slice_n]).unsqueeze(0)\n",
    "#         sample[\"seg\"]=torch.from_numpy((self.data[vol_id][\"seg\"])[slice_n]).unsqueeze(0)\n",
    "#         #print(\"img = \",sample[\"img\"].dtype)\n",
    "#         #print(\"seg = \",sample[\"seg\"].dtype)\n",
    "#         return sample\n",
    "\n",
    "#     def __len__(self):\n",
    "#         \"\"\"\n",
    "#         This method is called by PyTorch DataLoader class to return number of samples in the dataset\n",
    "\n",
    "#         Returns:\n",
    "#             int\n",
    "#         \"\"\"\n",
    "#         return len(self.slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Contains class that runs inferencing\n",
    "# \"\"\"\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# from networks.RecursiveUNet import UNet\n",
    "\n",
    "# from utils.utils import med_reshape\n",
    "\n",
    "# class UNetInferenceAgent:\n",
    "#     \"\"\"\n",
    "#     Stores model and parameters and some methods to handle inferencing\n",
    "#     \"\"\"\n",
    "#     def __init__(self, parameter_file_path='', model=None, device=\"cpu\", patch_size=64):\n",
    "\n",
    "#         self.model = model\n",
    "#         self.patch_size = patch_size\n",
    "#         self.device = device\n",
    "\n",
    "#         if model is None:\n",
    "#             self.model = UNet(num_classes=3)\n",
    "\n",
    "#         if parameter_file_path:\n",
    "#             self.model.load_state_dict(torch.load(parameter_file_path, map_location=self.device))\n",
    "\n",
    "#         self.model.to(device)\n",
    "\n",
    "#     def single_volume_inference_unpadded(self, volume):\n",
    "#         \"\"\"\n",
    "#         Runs inference on a single volume of arbitrary patch size,\n",
    "#         padding it to the conformant size first\n",
    "\n",
    "#         Arguments:\n",
    "#             volume {Numpy array} -- 3D array representing the volume\n",
    "\n",
    "#         Returns:\n",
    "#             3D NumPy array with prediction mask\n",
    "#         \"\"\"\n",
    "#         reshaped_image = med_reshape(volume, new_shape=(volume.shape[0], self.patch_size, self.patch_size)).astype(np.single)\n",
    "#         return reshaped_image\n",
    "#         #raise NotImplementedError\n",
    "\n",
    "#     def single_volume_inference(self, volume):\n",
    "#         \"\"\"\n",
    "#         Runs inference on a single volume of conformant patch size\n",
    "\n",
    "#         Arguments:\n",
    "#             volume {Numpy array} -- 3D array representing the volume\n",
    "\n",
    "#         Returns:\n",
    "#             3D NumPy array with prediction mask\n",
    "#         \"\"\"\n",
    "#         # Assuming volume is a numpy array of shape [X,Y,Z] and we need to slice X axis\n",
    "#         # TASK: Write code that will create mask for each slice across the X (0th) dimension. After \n",
    "#         # that, put all slices into a 3D Numpy array. You can verify if your method is \n",
    "#         # correct by running it on one of the volumes in your training set and comparing \n",
    "#         # with the label in 3D Slicer.\n",
    "#         volume=self.single_volume_inference_unpadded(volume)\n",
    "#         volume=volume.reshape([volume.shape[0],1,volume.shape[1],volume.shape[2]])\n",
    "#         #slices = []\n",
    "#         self.model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             #for batch_ind in range()\n",
    "#             data = torch.from_numpy(volume).to(self.device)\n",
    "#             print(data.shape)\n",
    "#             prediction = self.model(data)\n",
    "#             prediction_softmax = F.softmax(prediction, dim=1)\n",
    "#             res=(prediction_softmax).squeeze(0).cpu().detach().numpy()\n",
    "#             slices=res\n",
    "\n",
    "\n",
    "#         return slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# This module represents a UNet experiment and contains a class that handles\n",
    "# the experiment lifecycle\n",
    "# \"\"\"\n",
    "# import os\n",
    "# import time\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from data_prep.SlicesDataset import SlicesDataset\n",
    "# from utils.utils import log_to_tensorboard\n",
    "# from utils.volume_stats import Dice3d, Jaccard3d\n",
    "# from networks.RecursiveUNet import UNet\n",
    "# #from inference.UNetInferenceAgent import UNetInferenceAgent\n",
    "\n",
    "# class UNetExperiment:\n",
    "#     \"\"\"\n",
    "#     This class implements the basic life cycle for a segmentation task with UNet(https://arxiv.org/abs/1505.04597).\n",
    "#     The basic life cycle of a UNetExperiment is:\n",
    "\n",
    "#         run():\n",
    "#             for epoch in n_epochs:\n",
    "#                 train()\n",
    "#                 validate()\n",
    "#         test()\n",
    "#     \"\"\"\n",
    "#     def __init__(self, config, split, dataset):\n",
    "#         self.n_epochs = config.n_epochs\n",
    "#         self.split = split\n",
    "#         self._time_start = \"\"\n",
    "#         self._time_end = \"\"\n",
    "#         self.epoch = 0\n",
    "#         self.name = config.name\n",
    "\n",
    "#         # Create output folders\n",
    "#         dirname = f'{time.strftime(\"%Y-%m-%d_%H%M\", time.gmtime())}_{self.name}'\n",
    "#         self.out_dir = os.path.join(config.test_results_dir, dirname)\n",
    "#         os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "#         # Create data loaders\n",
    "#         # TASK: SlicesDataset class is not complete. Go to the file and complete it. \n",
    "#         # Note that we are using a 2D version of UNet here, which means that it will expect\n",
    "#         # batches of 2D slices.\n",
    "#         self.train_loader = DataLoader(SlicesDataset(dataset[split[\"train\"]]),\n",
    "#                 batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "#         self.val_loader = DataLoader(SlicesDataset(dataset[split[\"val\"]]),\n",
    "#                 batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "#         # we will access volumes directly for testing\n",
    "#         #self.test_data = dataset[split[\"test\"]]\n",
    "#         self.test_data = dataset[split[\"test\"]]\n",
    "#         # Do we have CUDA available?\n",
    "#         if not torch.cuda.is_available():\n",
    "#             print(\"WARNING: No CUDA device is found. This may take significantly longer!\")\n",
    "#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#         # Configure our model and other training implements\n",
    "#         # We will use a recursive UNet model from German Cancer Research Center, \n",
    "#         # Division of Medical Image Computing. It is quite complicated and works \n",
    "#         # very well on this task. Feel free to explore it or plug in your own model\n",
    "#         self.model = UNet(num_classes=3)\n",
    "#         self.model.to(self.device)\n",
    "\n",
    "#         # We are using a standard cross-entropy loss since the model output is essentially\n",
    "#         # a tensor with softmax'd prediction of each pixel's probability of belonging \n",
    "#         # to a certain class\n",
    "#         self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#         # We are using standard SGD method to optimize our weights\n",
    "#         self.optimizer = optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
    "#         # Scheduler helps us update learning rate automatically\n",
    "#         self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
    "\n",
    "#         # Set up Tensorboard. By default it saves data into runs folder. You need to launch\n",
    "#         self.tensorboard_train_writer = SummaryWriter(comment=\"_train\")\n",
    "#         self.tensorboard_val_writer = SummaryWriter(comment=\"_val\")\n",
    "\n",
    "#     def train(self):\n",
    "#         \"\"\"\n",
    "#         This method is executed once per epoch and takes \n",
    "#         care of model weight update cycle\n",
    "#         \"\"\"\n",
    "#         print(f\"Training epoch {self.epoch}...\")\n",
    "#         self.model.train()\n",
    "\n",
    "#         # Loop over our minibatches\n",
    "#         for i, batch in enumerate(self.train_loader):\n",
    "#             #print(\"batch shape\",batch)\n",
    "#             self.optimizer.zero_grad()\n",
    "\n",
    "#             # TASK: You have your data in batch variable. Put the slices as 4D Torch Tensors of \n",
    "#             # shape [BATCH_SIZE, 1, PATCH_SIZE, PATCH_SIZE] into variables data and target. \n",
    "#             # Feed data to the model and feed target to the loss function\n",
    "#             #print(\"batch =\",batch)\n",
    "#             data = batch[\"img\"].to(self.device)\n",
    "#             target = batch[\"seg\"].to(self.device)\n",
    "#             #print(\"data shape =\",data.shape)\n",
    "#             #print(\"target shape =\",target.shape)\n",
    "#             prediction = self.model(data)\n",
    "\n",
    "#             # We are also getting softmax'd version of prediction to output a probability map\n",
    "#             # so that we can see how the model converges to the solution\n",
    "#             prediction_softmax = F.softmax(prediction, dim=1)\n",
    "\n",
    "#             loss = self.loss_function(prediction, target[:, 0, :, :]).to(self.device)\n",
    "\n",
    "#             # TASK: What does each dimension of variable prediction represent?\n",
    "#             # ANSWER:\n",
    "#             #the dimensions is as the following:\n",
    "#             #[batch_size,class_predition_probability,slice_width,slice_height]\n",
    "\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "\n",
    "#             if (i % 10) == 0:\n",
    "#                 # Output to console on every 10th batch\n",
    "#                 print(f\"\\nEpoch: {self.epoch} Train loss: {loss}, {100*(i+1)/len(self.train_loader):.1f}% complete\")\n",
    "\n",
    "#                 counter = 100*self.epoch + 100*(i/len(self.train_loader))\n",
    "\n",
    "#                 # You don't need to do anything with this function, but you are welcome to \n",
    "#                 # check it out if you want to see how images are logged to Tensorboard\n",
    "#                 # or if you want to output additional debug data\n",
    "#                 log_to_tensorboard(\n",
    "#                     self.tensorboard_train_writer,\n",
    "#                     loss,\n",
    "#                     data,\n",
    "#                     target,\n",
    "#                     prediction_softmax,\n",
    "#                     prediction,\n",
    "#                     counter)\n",
    "\n",
    "#             print(\".\", end='')\n",
    "\n",
    "#         print(\"\\nTraining complete\")\n",
    "\n",
    "#     def validate(self):\n",
    "#         \"\"\"\n",
    "#         This method runs validation cycle, using same metrics as \n",
    "#         Train method. Note that model needs to be switched to eval\n",
    "#         mode and no_grad needs to be called so that gradients do not \n",
    "#         propagate\n",
    "#         \"\"\"\n",
    "#         print(f\"Validating epoch {self.epoch}...\")\n",
    "\n",
    "#         # Turn off gradient accumulation by switching model to \"eval\" mode\n",
    "#         self.model.eval()\n",
    "#         loss_list = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for i, batch in enumerate(self.val_loader):\n",
    "                \n",
    "#                 # TASK: Write validation code that will compute loss on a validation sample\n",
    "#                 data = batch[\"img\"].to(self.device)\n",
    "#                 target = batch[\"seg\"].to(self.device)\n",
    "#                 #print(\"data shape =\",data.shape)\n",
    "#                 #print(\"target shape =\",target.shape)\n",
    "#                 prediction = self.model(data)\n",
    "#                 prediction_softmax = F.softmax(prediction, dim=1)\n",
    "#                 loss = self.loss_function(prediction_softmax, target[:, 0, :, :])\n",
    "#                 #loss = loss_fx(prediction, target)\n",
    "#                 print(f\"Batch {i}. Data shape {data.shape} Loss {loss}\")\n",
    "\n",
    "#                 # We report loss that is accumulated across all of validation set\n",
    "#                 loss_list.append(loss.item())\n",
    "\n",
    "#         self.scheduler.step(np.mean(loss_list))\n",
    "\n",
    "#         log_to_tensorboard(\n",
    "#             self.tensorboard_val_writer,\n",
    "#             np.mean(loss_list),\n",
    "#             data,\n",
    "#             target,\n",
    "#             prediction_softmax, \n",
    "#             prediction,\n",
    "#             (self.epoch+1) * 100)\n",
    "#         print(f\"Validation complete\")\n",
    "\n",
    "#     def save_model_parameters(self):\n",
    "#         \"\"\"\n",
    "#         Saves model parameters to a file in results directory\n",
    "#         \"\"\"\n",
    "#         path = os.path.join(self.out_dir, \"model.pth\")\n",
    "\n",
    "#         torch.save(self.model.state_dict(), path)\n",
    "\n",
    "#     def load_model_parameters(self, path=''):\n",
    "#         \"\"\"\n",
    "#         Loads model parameters from a supplied path or a\n",
    "#         results directory\n",
    "#         \"\"\"\n",
    "#         if not path:\n",
    "#             model_path = os.path.join(self.out_dir, \"model.pth\")\n",
    "#         else:\n",
    "#             model_path = path\n",
    "\n",
    "#         if os.path.exists(model_path):\n",
    "#             self.model.load_state_dict(torch.load(model_path))\n",
    "#         else:\n",
    "#             raise Exception(f\"Could not find path {model_path}\")\n",
    "\n",
    "#     def run_test(self):\n",
    "#         \"\"\"\n",
    "#         This runs test cycle on the test dataset.\n",
    "#         Note that process and evaluations are quite different\n",
    "#         Here we are computing a lot more metrics and returning\n",
    "#         a dictionary that could later be persisted as JSON\n",
    "#         \"\"\"\n",
    "#         print(\"Testing...\")\n",
    "#         self.model.eval()\n",
    "\n",
    "#         # In this method we will be computing metrics that are relevant to the task of 3D volume\n",
    "#         # segmentation. Therefore, unlike train and validation methods, we will do inferences\n",
    "#         # on full 3D volumes, much like we will be doing it when we deploy the model in the \n",
    "#         # clinical environment. \n",
    "\n",
    "#         # TASK: Inference Agent is not complete. Go and finish it. Feel free to test the class\n",
    "#         # in a module of your own by running it against one of the data samples\n",
    "#         inference_agent = UNetInferenceAgent(model=self.model, device=self.device)\n",
    "\n",
    "#         out_dict = {}\n",
    "#         out_dict[\"volume_stats\"] = []\n",
    "#         dc_list = []\n",
    "#         jc_list = []\n",
    "\n",
    "#         # for every in test set\n",
    "#         with torch.no_grad():\n",
    "#             for i, x in enumerate(self.test_data):\n",
    "#                 pred_label = inference_agent.single_volume_inference(x[\"image\"])\n",
    "\n",
    "#                 # We compute and report Dice and Jaccard similarity coefficients which \n",
    "#                 # assess how close our volumes are to each other\n",
    "#                 # TASK: Dice3D and Jaccard3D functions are not implemented. \n",
    "#                 #  Complete the implementation as we discussed\n",
    "#                 # correctly (and if you picked your train/val/test split right ;)),\n",
    "#                 # your average Jaccard on your test set should be around 0.80\n",
    "#                 #print(\"pred label shape\",pred_label.shape)\n",
    "#                 #plt.imshow(pred_label[4,:,:],cmap='gray')\n",
    "#                 #print(pred_label[4,:,:])\n",
    "#                 dc = Dice3d(pred_label, x[\"seg\"])\n",
    "#                 jc = Jaccard3d(pred_label, x[\"seg\"])\n",
    "#                 dc_list.append(dc)\n",
    "#                 jc_list.append(jc)\n",
    "\n",
    "#                 # STAND-OUT SUGGESTION: By way of exercise, consider also outputting:\n",
    "#                 # * Sensitivity and specificity (and explain semantic meaning in terms of \n",
    "#                 #   under/over segmenting)\n",
    "#                 # * Dice-per-slice and render combined slices with lowest and highest DpS\n",
    "#                 # * Dice per class (anterior/posterior)\n",
    "\n",
    "#                 out_dict[\"volume_stats\"].append({\n",
    "#                     \"filename\": x['filename'],\n",
    "#                     \"dice\": dc,\n",
    "#                     \"jaccard\": jc\n",
    "#                     })\n",
    "#                 print(f\"{x['filename']} Dice {dc:.4f}. {100*(i+1)/len(self.test_data):.2f}% complete\")\n",
    "\n",
    "#         out_dict[\"overall\"] = {\n",
    "#             \"mean_dice\": np.mean(dc_list),\n",
    "#             \"mean_jaccard\": np.mean(jc_list)}\n",
    "\n",
    "#         print(\"\\nTesting complete.\")\n",
    "#         return out_dict\n",
    "\n",
    "#     def run(self):\n",
    "#         \"\"\"\n",
    "#         Kicks off train cycle and writes model parameter file at the end\n",
    "#         \"\"\"\n",
    "#         self._time_start = time.time()\n",
    "\n",
    "#         print(\"Experiment started.\")\n",
    "\n",
    "#         # Iterate over epochs\n",
    "#         for self.epoch in range(self.n_epochs):\n",
    "#             self.train()\n",
    "#             self.validate()\n",
    "\n",
    "#         # save model for inferencing\n",
    "#         self.save_model_parameters()\n",
    "\n",
    "#         self._time_end = time.time()\n",
    "#         print(f\"Run complete. Total time: {time.strftime('%H:%M:%S', time.gmtime(self._time_end - self._time_start))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
